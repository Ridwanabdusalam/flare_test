"""Post-capture analysis workflow for flare experiments."""
from __future__ import annotations

import math
from dataclasses import dataclass
from pathlib import Path
from typing import Sequence

import numpy as np

from .config import CaptureConfig, ROIAnalysisConfig
from .utils import ensure_directory, write_metadata


@dataclass
class AnalysisResult:
    """Summary of outputs generated by the analysis workflow."""

    root: Path
    roi_file: Path
    signals_file: Path
    photo_response_file: Path
    summary_file: Path


class FlareAnalysisWorkflow:
    """Replicates the MATLAB post-processing steps in Python."""

    def __init__(self, capture_config: CaptureConfig) -> None:
        if capture_config.analysis is None or not capture_config.analysis.enabled:
            raise ValueError("Analysis configuration must be enabled to run analysis")
        self.capture_config = capture_config
        self.analysis_config = capture_config.analysis

    # -- helpers -----------------------------------------------------------------
    def _sequence_exposures(self) -> Sequence[int]:
        label = self.analysis_config.sequence_label
        for sequence in self.capture_config.exposure_sequences:
            if sequence.label == label:
                return sequence.exposure_us
        raise RuntimeError(f"Exposure sequence '{label}' not found")

    def _read_raw16(self, path: Path) -> np.ndarray:
        data = np.fromfile(path, dtype=np.uint16)
        expected = self.capture_config.raw_width * self.capture_config.raw_height
        if data.size != expected:
            raise ValueError(
                f"RAW16 file {path} had {data.size} pixels; expected {expected}"
            )
        return data.reshape((self.capture_config.raw_height, self.capture_config.raw_width))

    @staticmethod
    def _roi_slice(roi: ROIAnalysisConfig) -> tuple[slice, slice]:
        start_row = roi.row - roi.half_width
        end_row = roi.row + roi.half_width
        start_col = roi.col - roi.half_width
        end_col = roi.col + roi.half_width
        if start_row < 0 or start_col < 0:
            raise ValueError("ROI extends beyond image bounds (negative index)")
        return slice(start_row, end_row), slice(start_col, end_col)

    def _collect_roi_signals(
        self,
        capture_dir: Path,
        exposures: Sequence[int],
    ) -> np.ndarray:
        scenes = self.analysis_config.scenes
        rois = self.analysis_config.rois
        signals = np.zeros((len(scenes), len(exposures), len(rois)), dtype=float)
        for scene_index, scene in enumerate(scenes):
            for exposure_index, exposure in enumerate(exposures):
                raw_dir = (
                    capture_dir
                    / scene.illumination
                    / f"{self.analysis_config.sequence_label}_{exposure}us"
                    / "raw16"
                )
                frames = sorted(raw_dir.glob("*.raw"))
                if not frames:
                    raise FileNotFoundError(
                        f"No RAW16 frames found in {raw_dir} for exposure {exposure}"
                    )
                accum = np.zeros((len(rois),), dtype=float)
                count = 0
                for frame in frames:
                    image = self._read_raw16(frame)
                    for roi_index, roi in enumerate(rois):
                        row_slice, col_slice = self._roi_slice(roi)
                        if row_slice.stop > image.shape[0] or col_slice.stop > image.shape[1]:
                            raise ValueError(
                                f"ROI '{roi.name}' extends beyond image bounds for frame {frame}"
                            )
                        region = image[row_slice, col_slice]
                        if region.size == 0:
                            raise ValueError(
                                f"ROI '{roi.name}' produced an empty region for {frame}"
                            )
                        accum[roi_index] += float(region.mean())
                    count += 1
                signals[scene_index, exposure_index, :] = accum / max(count, 1)
        direct_idx = self.analysis_config.direct_beam_index()
        signals[:, :, direct_idx] = (
            signals[:, :, direct_idx] / max(self.analysis_config.nd_filter_ratio, np.finfo(float).eps)
        )
        return signals

    @staticmethod
    def _fit_photo_response(
        exposure_ms: np.ndarray,
        signals: np.ndarray,
        saturation_threshold: float,
    ) -> np.ndarray:
        n_scenes, n_exposures, n_rois = signals.shape
        fits = np.full((n_scenes, n_rois, 2), np.nan, dtype=float)
        for scene in range(n_scenes):
            for roi in range(n_rois):
                line = signals[scene, :, roi]
                over = np.where(line > saturation_threshold)[0]
                if over.size > 0:
                    indices = np.arange(max(over[0], 1))
                else:
                    indices = np.arange(n_exposures)
                if indices.size < 2:
                    indices = np.arange(n_exposures)
                if indices.size < 2 or np.all(line[indices] == line[indices][0]):
                    # Degenerate data; leave NaNs so downstream consumers know it failed.
                    continue
                try:
                    fits[scene, roi, :] = np.polyfit(exposure_ms[indices], line[indices], 1)
                except np.linalg.LinAlgError:
                    continue
        return fits

    def _fit_scene_and_reflectance(
        self,
        photo_response: np.ndarray,
    ) -> dict:
        scenes = np.array([scene.illumination_lux for scene in self.analysis_config.scenes], dtype=float)
        roi_defs = self.analysis_config.rois
        scene_fits = []
        for roi_index in range(photo_response.shape[1]):
            slopes = photo_response[:, roi_index, 0]
            if np.any(np.isnan(slopes)) or slopes.size < 2:
                scene_fits.append([math.nan, math.nan])
                continue
            try:
                scene_fits.append(np.polyfit(scenes, slopes, 1).tolist())
            except np.linalg.LinAlgError:
                scene_fits.append([math.nan, math.nan])
        reflectance_indices = self.analysis_config.reflectance_indices()
        reflectance_levels = [roi_defs[idx].reflectance for idx in reflectance_indices]
        reflectance_slopes = [scene_fits[idx][0] if idx < len(scene_fits) else math.nan for idx in reflectance_indices]
        reflectance_fit = None
        if reflectance_indices and not any(level is None for level in reflectance_levels):
            levels = np.array(reflectance_levels, dtype=float)
            slopes = np.array(reflectance_slopes, dtype=float)
            valid = ~(np.isnan(slopes) | np.isnan(levels))
            if valid.sum() >= 2:
                try:
                    reflectance_fit = np.polyfit(levels[valid], slopes[valid], 1).tolist()
                except np.linalg.LinAlgError:
                    reflectance_fit = None
        black_hole_idx = self.analysis_config.black_hole_index()
        black_hole_fit = None
        if black_hole_idx is not None:
            slopes = photo_response[:, black_hole_idx, 0]
            if not np.any(np.isnan(slopes)) and slopes.size >= 2:
                try:
                    black_hole_fit = np.polyfit(scenes, slopes, 1).tolist()
                except np.linalg.LinAlgError:
                    black_hole_fit = None
        direct_idx = self.analysis_config.direct_beam_index()
        direct_fit = None
        slopes = photo_response[:, direct_idx, 0]
        if not np.any(np.isnan(slopes)) and slopes.size >= 2:
            try:
                direct_fit = np.polyfit(scenes, slopes, 1).tolist()
            except np.linalg.LinAlgError:
                direct_fit = None
        return {
            "scene_fits": scene_fits,
            "reflectance_fit": reflectance_fit,
            "black_hole_fit": black_hole_fit,
            "direct_beam_fit": direct_fit,
        }

    def _write_roi_preview(
        self,
        capture_dir: Path,
        analysis_dir: Path,
        exposures: Sequence[int],
    ) -> Path:
        preview_path = analysis_dir / "roi" / "roi_preview.png"
        ensure_directory(preview_path.parent)
        illumination = self.analysis_config.preview_illumination
        exposure = self.analysis_config.preview_exposure_us or (exposures[len(exposures) // 2] if exposures else None)
        if illumination is None or exposure is None:
            write_metadata(
                preview_path.with_suffix(".json"),
                {"message": "Preview not generated; provide 'preview' illumination and exposure"},
            )
            return preview_path
        raw_dir = (
            capture_dir / illumination / f"{self.analysis_config.sequence_label}_{exposure}us" / "raw16"
        )
        frames = sorted(raw_dir.glob("*.raw"))
        if not frames:
            write_metadata(
                preview_path.with_suffix(".json"),
                {"message": f"No frames found for preview in {raw_dir}"},
            )
            return preview_path
        image = self._read_raw16(frames[0])
        norm = image.astype(float)
        if norm.ptp() > 0:
            norm = (norm - norm.min()) / norm.ptp()
        else:
            norm[:] = 0.5
        rgba = np.dstack([norm, norm, norm, np.ones_like(norm)])
        for roi in self.analysis_config.rois:
            row_slice, col_slice = self._roi_slice(roi)
            rgba[row_slice, col_slice, 0] = 1.0
            rgba[row_slice, col_slice, 1] = 0.0
            rgba[row_slice, col_slice, 2] = 0.0
        try:
            import matplotlib

            matplotlib.use("Agg")  # type: ignore
            import matplotlib.pyplot as plt

            fig, ax = plt.subplots(figsize=(8, 6))
            ax.imshow(rgba, origin="upper")
            for roi in self.analysis_config.rois:
                row_slice, col_slice = self._roi_slice(roi)
                center_row = roi.row
                center_col = roi.col
                ax.text(center_col, center_row, roi.name, color="yellow", ha="center", va="center")
            ax.set_axis_off()
            fig.tight_layout()
            fig.savefig(preview_path, dpi=200)
            plt.close(fig)
        except Exception as exc:  # pragma: no cover - optional dependency
            write_metadata(
                preview_path.with_suffix(".json"),
                {"message": f"Failed to generate ROI preview: {exc}"},
            )
        return preview_path

    # -- public API --------------------------------------------------------------
    def run(self, context: "RunContext") -> AnalysisResult:
        from .workflow import RunContext  # Local import to avoid circular dependency

        if not isinstance(context, RunContext):
            raise TypeError("Analysis requires a RunContext from the capture workflow")
        exposures = self._sequence_exposures()
        exposure_ms = np.array(exposures, dtype=float) / 1000.0
        signals = self._collect_roi_signals(context.capture_dir, exposures)
        photo_response = self._fit_photo_response(
            exposure_ms,
            signals,
            self.analysis_config.saturation_dn,
        )
        offset_corrected = signals - photo_response[:, :, 1][:, np.newaxis, :]
        fit_summary = self._fit_scene_and_reflectance(photo_response)

        analysis_root = context.analysis_dir
        metrics_dir = analysis_root / "metrics"
        ensure_directory(metrics_dir)
        roi_dir = analysis_root / "roi"
        ensure_directory(roi_dir)

        roi_file = roi_dir / "rois.json"
        write_metadata(roi_file, [roi.__dict__ for roi in self.analysis_config.rois])
        signals_file = metrics_dir / "roi_signals.json"
        write_metadata(
            signals_file,
            {
                "scenes": [scene.illumination for scene in self.analysis_config.scenes],
                "exposures_us": list(exposures),
                "signals": signals.tolist(),
                "offset_corrected": offset_corrected.tolist(),
            },
        )
        photo_response_file = metrics_dir / "photo_response.json"
        write_metadata(
            photo_response_file,
            {
                "coefficients": photo_response.tolist(),
                "sequence_label": self.analysis_config.sequence_label,
            },
        )
        summary = {
            "scene_illumination_fits": fit_summary["scene_fits"],
            "reflectance_fit": fit_summary["reflectance_fit"],
            "black_hole_fit": fit_summary["black_hole_fit"],
            "direct_beam_fit": fit_summary["direct_beam_fit"],
            "nd_filter_ratio": self.analysis_config.nd_filter_ratio,
            "saturation_dn": self.analysis_config.saturation_dn,
        }
        summary_file = analysis_root / "summary.json"
        write_metadata(summary_file, summary)
        self._write_roi_preview(context.capture_dir, analysis_root, exposures)
        return AnalysisResult(
            root=analysis_root,
            roi_file=roi_file,
            signals_file=signals_file,
            photo_response_file=photo_response_file,
            summary_file=summary_file,
        )


__all__ = ["FlareAnalysisWorkflow", "AnalysisResult"]
